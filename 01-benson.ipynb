{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load packages and data files\n",
    "import csv\n",
    "import glob\n",
    "from pprint import pprint \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from operator import add\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Function to Read all text files and Store in a List\n",
    "def turnstile_read_csv(csv_files):\n",
    "    dict_MTA= defaultdict(list)\n",
    "    MTA = [] \n",
    "    for filename in glob.glob(csv_files):\n",
    "        file = open(filename, 'r')\n",
    "        reader = csv.reader(file)\n",
    "        header = reader.next()\n",
    "        MTA = list(reader)\n",
    "        for turnstile in MTA:\n",
    "            turnstile[-1].strip()     # Strip does not seem to work, fix later\n",
    "            turnstile_key = tuple(turnstile[0:5])\n",
    "            dict_MTA[turnstile_key].append(turnstile[5:])\n",
    "        file.close()\n",
    "    return dict_MTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('JFK03', 'R536', '00-00-02', 'JFK JAMAICA CT1', 'E'): [['IND',\n",
      "                                                          '06/04/2016',\n",
      "                                                          '01:00:00',\n",
      "                                                          'REGULAR',\n",
      "                                                          '0000087367',\n",
      "                                                          '0000079390                                       '],\n",
      "                                                         ['IND',\n",
      "                                                          '06/04/2016',\n",
      "                                                          '05:00:00',\n",
      "                                                          'REGULAR',\n",
      "                                                          '0000087372',\n",
      "                                                          '0000079392                                       ']],\n",
      " ('R238A', 'R046', '02-03-02', 'GRD CNTRL-42 ST', '4567S'): [['IRT',\n",
      "                                                              '06/04/2016',\n",
      "                                                              '00:00:00',\n",
      "                                                              'REGULAR',\n",
      "                                                              '0000000027',\n",
      "                                                              '0000000015                                   '],\n",
      "                                                             ['IRT',\n",
      "                                                              '06/04/2016',\n",
      "                                                              '04:00:00',\n",
      "                                                              'REGULAR',\n",
      "                                                              '0000000027',\n",
      "                                                              '0000000015                                   ']]}\n"
     ]
    }
   ],
   "source": [
    "## Read all text files and Store in a List\n",
    "dict_MTA = turnstile_read_csv(\"turnstile_*.txt\")\n",
    "pprint ({k: dict_MTA[k][:2] for k in dict_MTA.keys()[:2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts per interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from dateutil import parser\n",
    "def time_series(dict_MTA):\n",
    "    dict_MTA_ts = {}\n",
    "    for key in dict_MTA.keys():\n",
    "        dict_MTA_ts[key] = []\n",
    "        for i in range(0, len(dict_MTA[key])):\n",
    "            time = dict_MTA[key][i][1] + \" \" + dict_MTA[key][i][2]\n",
    "            four_hr_ct = int(dict_MTA[key][i][4])- int(dict_MTA[key][i-1][4])\n",
    "            #print \"Count: %d\" %four_hr_ct\n",
    "            #gets entries and exits for each station\n",
    "            four_hr_ct_entry = int(dict_MTA[key][i][4])- int(dict_MTA[key][i-1][4])\n",
    "            four_hr_ct_exit = int(dict_MTA[key][i][5]) - int(dict_MTA[key][i-1][5])\n",
    "            #checks that exits and entries are not negative and adds accordingly\n",
    "            if four_hr_ct_entry < 0 or four_hr_ct_entry > 4*60*20 and four_hr_ct_exit < 0 or four_hr_ct_exit > 4*60*20:\n",
    "                dict_MTA_ts[key].append([parser.parse(time), None])\n",
    "            elif four_hr_ct_entry < 0 or four_hr_ct_entry > 4*60*20:\n",
    "                dict_MTA_ts[key].append([parser.parse(time), four_hr_ct_exit])\n",
    "            elif four_hr_ct_exit < 0 or four_hr_ct_exit > 4*60*20:\n",
    "                dict_MTA_ts[key].append([parser.parse(time), four_hr_ct_entry])\n",
    "            else:\n",
    "                dict_MTA_ts[key].append([parser.parse(time), four_hr_ct_entry + four_hr_ct_exit])\n",
    "    return dict_MTA_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[datetime.datetime(2016, 6, 4, 1, 0), None], [datetime.datetime(2016, 6, 4, 5, 0), 33], [datetime.datetime(2016, 6, 4, 9, 0), 226], [datetime.datetime(2016, 6, 4, 13, 0), 208], [datetime.datetime(2016, 6, 4, 17, 0), 261], [datetime.datetime(2016, 6, 4, 21, 0), 232], [datetime.datetime(2016, 6, 5, 1, 0), 125], [datetime.datetime(2016, 6, 5, 5, 0), 30], [datetime.datetime(2016, 6, 5, 9, 0), 140], [datetime.datetime(2016, 6, 5, 13, 0), 166]]\n",
      "[[datetime.datetime(2016, 6, 4, 2, 0), None], [datetime.datetime(2016, 6, 4, 6, 0), 16], [datetime.datetime(2016, 6, 4, 10, 0), 146], [datetime.datetime(2016, 6, 4, 14, 0), 382], [datetime.datetime(2016, 6, 4, 18, 0), 592], [datetime.datetime(2016, 6, 4, 22, 0), 500], [datetime.datetime(2016, 6, 5, 2, 0), 110], [datetime.datetime(2016, 6, 5, 6, 0), 10], [datetime.datetime(2016, 6, 5, 10, 0), 112], [datetime.datetime(2016, 6, 5, 14, 0), 385]]\n"
     ]
    }
   ],
   "source": [
    "small = dict((k, dict_MTA[k]) for k in (('N134', 'R385', '00-00-00', 'ROCKAWAY BLVD', 'A'), ('A006', 'R079' , '00-00-01' , '5 AV/59 ST','NQR')))\n",
    "ts_small = time_series(small)\n",
    "print ts_small[('N134', 'R385', '00-00-00', 'ROCKAWAY BLVD','A')][:10]\n",
    "print ts_small[('A006', 'R079' , '00-00-01' , '5 AV/59 ST','NQR')][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-578cd2f53c98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run all time series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdict_MTA_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_MTA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-2d5feda922e1>\u001b[0m in \u001b[0;36mtime_series\u001b[1;34m(dict_MTA)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mdict_MTA_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mdict_MTA_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfour_hr_ct\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict_MTA_ts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sameh\\Anaconda2\\lib\\site-packages\\dateutil\\parser.pyc\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sameh\\Anaconda2\\lib\\site-packages\\dateutil\\parser.pyc\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0meffective_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipped_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sameh\\Anaconda2\\lib\\site-packages\\dateutil\\parser.pyc\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m             \u001b[1;31m# Process year/month/day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mymd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve_ymd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmstridx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myearfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdayfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sameh\\Anaconda2\\lib\\site-packages\\dateutil\\parser.pyc\u001b[0m in \u001b[0;36mresolve_ymd\u001b[1;34m(self, mstridx, yearfirst, dayfirst)\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m31\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_probable_year_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_timelex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtzstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m                    \u001b[1;33m(\u001b[0m\u001b[0myearfirst\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m12\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                     \u001b[1;31m# 99-01-01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sameh\\Anaconda2\\lib\\site-packages\\dateutil\\parser.pyc\u001b[0m in \u001b[0;36mfind_probable_year_index\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[0mpotential_year_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ymd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_potential_year_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpotential_year_tokens\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpotential_year_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run all time series\n",
    "dict_MTA_ts = time_series(dict_MTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine stations and lines and attempt to adjust for incongruent line-station combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix some naming of station-lines, more needed on future steps\n",
    "def convert(station, line):\n",
    "    try:\n",
    "        if station == \"34 ST-PENN STA\": return \"123ACE\"\n",
    "        return {'ACJZ2345': '2345ACJZ', 'ACENQRS1237': '1237ACENQRS','AC1' : '1AC', \n",
    "         'JZ456' : '456JZ', 'BDNQR2345' : '2345BDNQR', 'ABCD1' : '1ABCD', \n",
    "         'R2345' : '2345R', 'LNQR456' : '456LNQR', 'BD4' : '4BD',\n",
    "         'ACENGRS1237': '1237ACENQRS'}[line]\n",
    "    except:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge per station per morning of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_into_stations(MTA):\n",
    "    dict_station = defaultdict(list)\n",
    "    for key in MTA:\n",
    "        station_key = key[3] + \" _ \" + convert(key[3], key[4])\n",
    "        #print station_key\n",
    "        for interval in MTA[key]:\n",
    "            #Eprint \"Interval: \",\n",
    "            #print interval \n",
    "            #print 14 >= interval[0].hour and interval[0].hour >= 8\n",
    "            if(14 >= interval[0].hour and interval[0].hour >= 8):\n",
    "                dict_station[station_key].append([interval[0].weekday(), interval[0].hour, interval[1]])\n",
    "            #print dict_station\n",
    "    return dict_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_small = combine_into_stations(ts_small)\n",
    "print station_small   # for each day of the month [day f the week, time, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying fn to merge per morning of week by station\n",
    "dict_stations = combine_into_stations(dict_MTA_ts)\n",
    "print dict_stations['5 AV/59 ST _ NQR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates dictionary of format station:[avg count from Mon AM, for Tues AM, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def days_of_week(dict_station):\n",
    "    dict_by_day = defaultdict(list)\n",
    "    for key in dict_station:\n",
    "        day_counter = [0,0,0,0,0,0,0]\n",
    "        dict_by_day[key] = [None,None,None,None,None,None,None]\n",
    "        #print len(dict_station[key])\n",
    "        \n",
    "        for entry in dict_station[key]:\n",
    "            day_counter[entry[0]]+=1\n",
    "            #print dict_by_day[key]\n",
    "            #print entry[2]\n",
    "            if dict_by_day[key][entry[0]] == None and entry[2] != None:\n",
    "                dict_by_day[key][entry[0]] = float(entry[2])\n",
    "            elif entry[2] != None:\n",
    "                dict_by_day[key][entry[0]] += float(entry[2])\n",
    "        for i in range(0,7):\n",
    "            dict_by_day[key][i] = dict_by_day[key][i]/(float(day_counter[i])/2)  \n",
    "    #print day_counter\n",
    "    \n",
    "    return dict_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days_small = days_of_week(station_small)\n",
    "print days_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_by_days = days_of_week(dict_stations)\n",
    "#print len(dict_by_days)\n",
    "#print dict_by_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints out all stations to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print dict_by_days.keys()\n",
    "#import csv\n",
    "with open('stations.csv','w') as file:\n",
    "    writer = csv.writer(file, lineterminator=',')\n",
    "    for i in dict_by_days.keys():\n",
    "        writer.writerow([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add by Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbor_key=defaultdict()\n",
    "\n",
    "with open ('Neighborhoods.csv') as csv_file:\n",
    "    data=csv.reader(csv_file)\n",
    "    for line in data:\n",
    "        neighbor_key[line[0]]=line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_stations=neighbor_key.keys()\n",
    "averages=dict_by_days    #### CHANGE OF VAR NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averages['125 ST _ 23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbor_influx=defaultdict(list)\n",
    "\n",
    "for station in neighbor_key.keys():\n",
    "    hood = neighbor_key[station]\n",
    "    if neighbor_influx[hood]:\n",
    "        neighbor_influx[hood]= map(add, neighbor_influx[hood],averages[station])   ## Sum of averages!!!! \n",
    "    else:\n",
    "        neighbor_influx[hood]=averages[station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbor_influx['CHELSEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
